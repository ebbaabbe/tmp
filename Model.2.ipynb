{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read simulator images from udacity training set\n",
    "import csv\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def process_image(img_path, size=(32,32)):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #img = cv2.resize(img, size, interpolation=cv2.INTER_AREA)\n",
    "    return img\n",
    "    \n",
    "\n",
    "def read_data(batch_size):\n",
    "    \"\"\"\n",
    "    Generator function to load driving logs and input images.\n",
    "    \"\"\"\n",
    "    while 1:\n",
    "        with open('data/driving_log.csv') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            count = 0\n",
    "            # Create training set\n",
    "            images = np.empty([0, 160, 320, 3], dtype=float)\n",
    "            measurements = np.empty([0, ], dtype=float)\n",
    "            \n",
    "            try:\n",
    "                for row in reader:\n",
    "                    if count < int(batch_size/2):\n",
    "                        image = process_image('data/'+ row['center'])\n",
    "                        flip_image = np.fliplr(image)\n",
    "                        steering_angle = float(row['steering'])\n",
    "                        images = np.append(images, np.array([image, flip_image]), axis=0)\n",
    "                        measurements = np.append(measurements, np.array([steering_angle, -steering_angle]), axis=0)\n",
    "                        count += 1\n",
    "                    else:\n",
    "                        yield images, measurements\n",
    "                        \n",
    "                    if count < int(batch_size/2):\n",
    "                        image = process_image('data/'+ row['left'])\n",
    "                        flip_image = np.fliplr(image)\n",
    "                        steering_angle = float(row['steering'] + 0.2)\n",
    "                        images = np.append(images, np.array([image, flip_image]), axis=0)\n",
    "                        measurements = np.append(measurements, np.array([steering_angle, -steering_angle]), axis=0)\n",
    "                        count += 1\n",
    "                    else:\n",
    "                        yield images, measurements\n",
    "                    \n",
    "                    if count < int(batch_size/2):\n",
    "                        image = process_image('data/'+ row['right'])\n",
    "                        flip_image = np.fliplr(image)\n",
    "                        steering_angle = float(row['steering'] - 0.2)\n",
    "                        images = np.append(images, np.array([image, flip_image]), axis=0)\n",
    "                        measurements = np.append(measurements, np.array([steering_angle, -steering_angle]), axis=0)\n",
    "                        count += 1\n",
    "                    else:\n",
    "                        yield (images, measurements)\n",
    "            except StopIteration:\n",
    "                pass\n",
    "\n",
    "def read_data2(batch_size):\n",
    "    \"\"\"\n",
    "    Generator function to load driving logs and input images.\n",
    "    \"\"\"\n",
    "    while 1:\n",
    "        with open('data/driving_log.csv') as driving_log_file:\n",
    "            driving_log_reader = csv.DictReader(driving_log_file)\n",
    "            count = 0\n",
    "            inputs = []\n",
    "            targets = []\n",
    "            try:\n",
    "                for row in driving_log_reader:\n",
    "                    image = process_image('data/'+ row['center'])\n",
    "                    flip_image = np.fliplr(image)\n",
    "                    steering_angle = float(row['steering'])\n",
    "                    if count == 0:\n",
    "                        inputs = np.empty([0, 160, 320, 3], dtype=float)\n",
    "                        targets = np.empty([0, ], dtype=float)\n",
    "                    if count < int(batch_size/2):\n",
    "                        inputs = np.append(inputs, np.array([image, flip_image]), axis=0)\n",
    "                        targets = np.append(targets, np.array([steering_angle, -steering_angle]), axis=0)\n",
    "                        count += 1\n",
    "                    else:\n",
    "                        yield inputs, targets\n",
    "                        count = 0\n",
    "            except StopIteration:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "613s - loss: 0.0163\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mrasquinha/anaconda3/anaconda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/mrasquinha/anaconda3/anaconda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mrasquinha/anaconda3/anaconda/lib/python3.6/site-packages/keras/engine/training.py\", line 612, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"<ipython-input-3-5d2800957036>\", line 73, in read_data2\n",
      "    image = process_image('data/'+ row['center'])\n",
      "  File \"<ipython-input-3-5d2800957036>\", line 10, in process_image\n",
      "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
      "cv2.error: /Users/travis/miniconda3/conda-bld/opencv_1492074520667/work/opencv-3.2.0/modules/imgproc/src/color.cpp:9716: error: (-215) scn == 3 || scn == 4 in function cvtColor\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "output of generator should be a tuple `(x, y, sample_weight)` or `(x, y)`. Found: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-846186feab6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                         verbose=2)\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mrasquinha/anaconda3/anaconda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mrasquinha/anaconda3/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1108\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mrasquinha/anaconda3/anaconda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mrasquinha/anaconda3/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1863\u001b[0m                                          \u001b[0;34m'a tuple `(x, y, sample_weight)` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m                                          \u001b[0;34m'or `(x, y)`. Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1865\u001b[0;31m                                          str(generator_output))\n\u001b[0m\u001b[1;32m   1866\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1867\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: output of generator should be a tuple `(x, y, sample_weight)` or `(x, y)`. Found: None"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Cropping2D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Lambda\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers.noise import GaussianDropout\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# 60 pixel from top and 20 pixels from bottom of the image was cropped\n",
    "model.add(Cropping2D(cropping=((60, 25), (0, 0)), input_shape=(160, 320, 3)))\n",
    "model.add(Lambda(lambda x: (x / 255.0))) # normalize the input to 0 and 1\n",
    "model.add(GaussianNoise(0.1)) #additive normal noise with 0.1 STD to prevent overfitting\n",
    "\n",
    "# I incorporated the nvidia netowrk\n",
    "model.add(Conv2D(24, (5, 5), padding=\"valid\", strides=(2, 2),\n",
    "                 activation=\"relu\", kernel_initializer=\"glorot_normal\"))  # 24x36x158\n",
    "model.add(Conv2D(36, (5, 5), padding=\"valid\", strides=(2, 2),\n",
    "                 activation=\"relu\", kernel_initializer=\"glorot_normal\"))  # 36x16x77\n",
    "model.add(Conv2D(48, (5, 5), padding=\"valid\", strides=(2, 2),\n",
    "                 activation=\"relu\", kernel_initializer=\"glorot_normal\"))  # 48x6x37\n",
    "# since the origianl image was slightly bigger than the one used by nividia\n",
    "\n",
    "# I changed the filter size of layer 4 tom atch the features height at layer 5\n",
    "model.add(Conv2D(64, (4, 4), padding=\"valid\", activation=\"relu\",\n",
    "                 kernel_initializer=\"glorot_normal\"))  # 64x3x34\n",
    "model.add(Conv2D(64, (3, 3), padding=\"valid\", activation=\"relu\",\n",
    "                 kernel_initializer=\"glorot_normal\"))  # 64x1x32\n",
    "\n",
    "model.add(Flatten())\n",
    "# multiplicative normal noise with mean 1 and STD around 0.5 to prevent overfitting\n",
    "model.add(GaussianDropout(0.25))\n",
    "\n",
    "model.add(Dense(100, activation=\"relu\", kernel_initializer=\"glorot_normal\"))\n",
    "model.add(Dense(50, activation=\"relu\", kernel_initializer=\"glorot_normal\"))\n",
    "model.add(Dense(10, activation=\"relu\", kernel_initializer=\"glorot_normal\"))\n",
    "\n",
    "model.add(Dense(1, kernel_initializer=\"glorot_normal\"))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "history_object = model.fit_generator(read_data2(128),\n",
    "                        steps_per_epoch=100,\n",
    "                        epochs=25,\n",
    "                        verbose=2)\n",
    "\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# Show the model in ipython notebook\n",
    "figure = SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "display(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Behavioral Cloning Project**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "* Use the simulator to collect data of good driving behavior\n",
    "* Build, a convolution neural network in Keras that predicts steering angles from images\n",
    "* Train and validate the model with a training and validation set\n",
    "* Test that the model successfully drives around track one without leaving the road\n",
    "* Summarize the results with a written report\n",
    "\n",
    "\n",
    "#### Files Submitted & Code Quality\n",
    "\n",
    "*1. Submission includes all required files and can be used to run the simulator in autonomous mode*\n",
    "\n",
    "My project includes the following files:\n",
    "* Model.ipynb containing the script to create and train the model\n",
    "* drive.py for driving the car in autonomous mode; Changed the speed to 15 from the default udacity code\n",
    "* model.h5 containing a trained convolution neural network\n",
    "* writeup_report.md or writeup_report.pdf summarizing the results\n",
    "\n",
    "*2. Submission includes functional code*\n",
    "Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track by executing\n",
    "```sh\n",
    "python drive.py model.h5\n",
    "```\n",
    "\n",
    "*3. Submission code is usable and readable*\n",
    "The Model.ipynb file contains the code for training and saving the convolution neural network. The file shows the pipeline I used for training and validating the model, and it contains comments to explain how the code works.\n",
    "\n",
    "#### Model Architecture and Training Strategy\n",
    "\n",
    "*1. An appropriate model architecture has been employed*\n",
    "\n",
    "My model is a slightly modified version of the Nvidia architecture described in class (http://images.nvidia.com/content/tegra/automotive/images/ 2016/solutions/pdf/end-to-end-dl-using-px.pdf).\n",
    "Figure 4 and \"section 4 Network Architecture\" provided all the details for the base implementation. I expermiented with different max pooloing   and dropout  layers. Finally settled on a single additional batch normalization layer after the first Convolution layer.\n",
    "\n",
    "I also used the cropping layer + normalization layer as described in the lectures. This is done before the convolution layers.\n",
    "\n",
    "*2. Attempts to reduce overfitting in the model*\n",
    "\n",
    "Experimented with dropout layers. The best accuracy was with the additional batch norm layer.\n",
    "\n",
    "The model was trained and validated on different data sets to ensure that the model was not overfitting. The model was tested by running it through the simulator and ensuring that the vehicle could stay on the track.\n",
    "\n",
    "*3. Model parameter tuning*\n",
    "\n",
    "The model used an adam optimizer, so the learning rate was not tuned manually.\n",
    "\n",
    "*4. Appropriate training data*\n",
    "\n",
    "I eventually used the images provided. Center+left+right camera images. I flipped some randomly picked images as can be seen in the graph after  cnt 8000. I set the validation split to be 25%. I also used some images from training the model using the simulator. I have appended the images I have generated to the end of the driving_log.csv. The simulator does not have a good response on my laptop and hence you can see the much bigger steering angles in the plot for x_val > 8000. \n",
    "\n",
    "I converted the images to RGB as a preprocessing step. I have also tried to use cv2 on a second set of images to visualize the effects. I was not sure how to get intermediate outputs from keras.\n",
    "\n",
    "#### Model Architecture and Training Strategy\n",
    "\n",
    "*1. Solution Design Approach*\n",
    "1. Try to collect training images using simulator\n",
    "2. Used udacity training data\n",
    "3. Crop and normalize layers using keras\n",
    "4. Nvidia deep learning network model\n",
    "5. Experiment with different batch norm/max pooling/drop out layers. Captured model.h5 files and moitored validation accuracy.\n",
    "6. Tweaked the steering angle in the original training data and tried the network.\n",
    "7. Picked the best model that runs on the simulator in auto mode\n",
    "\n",
    "*2. Final Model Architecture*\n",
    "Described above\n",
    "\n",
    "*3. Creation of the Training Set & Training Process*\n",
    "Collecting my own images did not work very well. I have used a few of them for training the network.\n",
    "\n",
    "I tried the use the fit generator aproach after reading this really amazing quora answer.\n",
    "https://www.quora.com/Intuitively-how-does-mini-batch-size-affect-the-performance-of-stochastic-gradient-descent\n",
    "However the smaller batch size, greater number of epochs was taking too long to run and did not yeild a higer accuracy in reasonable time. \n",
    "Thankfully while using the entire X_train set, I did not run into memory issues and this approach seemed to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
